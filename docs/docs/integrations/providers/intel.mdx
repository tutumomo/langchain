# Intel

>[Optimum Intel](https://github.com/huggingface/optimum-intel?tab=readme-ov-file#optimum-intel) is the interface between the ðŸ¤— Transformers and Diffusers libraries and the different tools and libraries provided by Intel to accelerate end-to-end pipelines on Intel architectures.

>[IntelÂ® Extension for Transformers](https://github.com/intel/intel-extension-for-transformers?tab=readme-ov-file#intel-extension-for-transformers) (ITREX) is an innovative toolkit designed to accelerate GenAI/LLM everywhere with the optimal performance of Transformer-based models on various Intel platforms, including Intel Gaudi2, Intel CPU, and Intel GPU.

This page covers how to use optimum-intel and ITREX with LangChain.

## Optimum-intel

All functionality related to the [optimum-intel](https://github.com/huggingface/optimum-intel.git) and [IPEX](https://github.com/intel/intel-extension-for-pytorch).

### Installation

Install using optimum-intel and ipex using:

```bash
pip install optimum[neural-compressor]
pip install intel_extension_for_pytorch
```

Please follow the installation instructions as specified below:

* Install optimum-intel as shown [here](https://github.com/huggingface/optimum-intel).
* Install IPEX as shown [here](https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=cpu&version=v2.2.0%2Bcpu).

### Embedding Models

See a [usage example](/docs/integrations/text_embedding/optimum_intel).
We also offer a full tutorial notebook "rag_with_quantized_embeddings.ipynb" for using the embedder in a RAG pipeline in the cookbook dir.

```python
from langchain_community.embeddings import QuantizedBiEncoderEmbeddings
```

## IntelÂ® Extension for Transformers (ITREX)

All functionality related to the [intel-extension-for-transformers](https://github.com/intel/intel-extension-for-transformers).

### Installation

Install intel-extension-for-transformers. For system requirements and other installation tips, please refer to [Installation Guide](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/installation.md)

```bash
pip install intel-extension-for-transformers
```

Install other required packages.

```bash
pip install -U torch onnx accelerate datasets
```

### Embedding Models

See a [usage example](/docs/integrations/text_embedding/itrex).

```python
from langchain_community.embeddings import QuantizedBgeEmbeddings
```
